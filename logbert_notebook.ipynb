{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xednM2XrX6qa"
      },
      "source": [
        "## Prepare Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fmCLnvZFYHZb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9TmsrTAZV3y",
        "outputId": "0e6b8fe1-326c-47a5-efac-111c60299403"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device cuda\n",
            "features logkey:True time: False\n",
            "\n",
            "mask ratio 0.65\n"
          ]
        }
      ],
      "source": [
        "# === PRE-PROCESS CONFIGURATION ===\n",
        "INPUT_CSV = \"path/to/raw/in.csv\" # Must have _value and _time column\n",
        "SEQUENCE_LENGTH = 20\n",
        "OUTPUT_DIR = \"out/\"\n",
        "\n",
        "import argparse\n",
        "import torch\n",
        "\n",
        "from bert_pytorch.dataset import WordVocab\n",
        "from bert_pytorch import Predictor, Trainer, Processor\n",
        "from bert_pytorch.dataset.utils import seed_everything\n",
        "\n",
        "options = dict()\n",
        "options['device'] = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "options[\"output_dir\"] = OUTPUT_DIR\n",
        "options[\"model_dir\"] = options[\"output_dir\"] + \"bert/\"\n",
        "options[\"model_path\"] = options[\"model_dir\"] + \"best_bert.pth\"\n",
        "options[\"train_vocab\"] = options[\"output_dir\"] + \"train\"\n",
        "options[\"vocab_path\"] = options[\"output_dir\"] + \"vocab.pkl\"  # pickle file\n",
        "\n",
        "options[\"drain_config\"] = \"out/drain/drain3.ini\"\n",
        "options[\"drain_state\"] = \"out/drain/concept_evaluation.bin\"\n",
        "\n",
        "options[\"window_size\"] = 128\n",
        "options[\"adaptive_window\"] = True\n",
        "options[\"seq_len\"] = SEQUENCE_LENGTH\n",
        "options[\"max_len\"] = 512 # for position embedding\n",
        "options[\"min_len\"] = 10\n",
        "options[\"mask_ratio\"] = 0.85\n",
        "# sample ratio\n",
        "options[\"train_ratio\"] = 0.7\n",
        "options[\"test_ratio\"] = 0.25\n",
        "options[\"valid_ratio\"] = 0.05\n",
        "\n",
        "# features\n",
        "options[\"is_logkey\"] = True\n",
        "options[\"is_time\"] = False\n",
        "\n",
        "options[\"hypersphere_loss\"] = True\n",
        "options[\"hypersphere_loss_test\"] = False\n",
        "\n",
        "options[\"scale\"] = None # MinMaxScaler()\n",
        "options[\"scale_path\"] = options[\"model_dir\"] + \"scale.pkl\"\n",
        "\n",
        "# model\n",
        "options[\"hidden\"] = 256 # embedding size\n",
        "options[\"layers\"] = 4\n",
        "options[\"attn_heads\"] = 4\n",
        "\n",
        "options[\"epochs\"] = 100\n",
        "options[\"n_epochs_stop\"] = 10\n",
        "options[\"batch_size\"] = 32\n",
        "\n",
        "options[\"corpus_lines\"] = None\n",
        "options[\"on_memory\"] = True\n",
        "options[\"num_workers\"] = 5\n",
        "options[\"lr\"] = 1e-3\n",
        "options[\"adam_beta1\"] = 0.9\n",
        "options[\"adam_beta2\"] = 0.999\n",
        "options[\"adam_weight_decay\"] = 0.00\n",
        "options[\"with_cuda\"]= True\n",
        "options[\"cuda_devices\"] = None\n",
        "options[\"log_freq\"] = None\n",
        "\n",
        "# predict\n",
        "options[\"num_candidates\"] = 6\n",
        "options[\"gaussian_mean\"] = 0\n",
        "options[\"gaussian_std\"] = 1\n",
        "\n",
        "seed_everything(seed=1234)\n",
        "\n",
        "if not os.path.exists(options['model_dir']):\n",
        "    os.makedirs(options['model_dir'], exist_ok=True)\n",
        "\n",
        "print(\"device\", options[\"device\"])\n",
        "print(\"features logkey:{} time: {}\\n\".format(options[\"is_logkey\"], options[\"is_time\"]))\n",
        "print(\"mask ratio\", options[\"mask_ratio\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yfr50XnHco1Q"
      },
      "outputs": [],
      "source": [
        "def process():\n",
        "    proc = Processor(options)\n",
        "    proc.preprocess(INPUT_CSV)\n",
        "    proc.process(SEQUENCE_LENGTH)\n",
        "\n",
        "def train():\n",
        "    Trainer(options).train()\n",
        "\n",
        "def predict(mean=0, std=1):\n",
        "    options[\"gaussian_mean\"] = mean\n",
        "    options[\"gaussian_std\"] = std\n",
        "\n",
        "    Predictor(options).predict()\n",
        "\n",
        "def vocab(vocab_size=None, encoding=\"utf-8\", min_freq=1):\n",
        "    with open(options[\"train_vocab\"], \"r\", encoding=encoding) as f:\n",
        "        texts = f.readlines()\n",
        "        print(texts)\n",
        "\n",
        "    vocab = WordVocab(texts, max_size=vocab_size, min_freq=min_freq)\n",
        "    vocab.save_vocab(options[\"vocab_path\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "processor = Processor(options)\n",
        "predictor = Predictor(options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"out/data/extract_ApplicationServer_nlxdsmcv39.csv\")\n",
        "\n",
        "logs = df['_value'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'E4 E4 E4 E4 E4 E4 E4 E4 E4 E4 E4 E4 E4 E4 E4 E4 E4 E4 E4 E4 E4 E28 E28 E4 E4 E4 E28 E4 E4 E4 E9 E4 E4 E4 E4 E4 E4 E4 E4 E9 E9 E8 E9 E4 E4 E9 E4 E9 E9 E4 E4 E4 E9 E49 E4 E4 E4 E8 E8 E4 E8 E9 E9 E55 E8 E9 E78 E4 E78 E4 E72 E78 E4 E72 E78 E4 E72 E78 E4 E72 E78 E4 E72 E9 E4 E4 E4 E4 E4 E49 E41 E8 E8 E41 E9 E9 E8 E4 E9 E4'"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logseq = processor.log_messages_to_keys(logs[10000:10100])\n",
        "logseq = ' '.join(logseq)\n",
        "logseq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'undetected_tokens': 2,\n",
              " 'masked_tokens': 15,\n",
              " 'anomaly': False,\n",
              " 'predictions': [],\n",
              " 'true_labels': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " 'hypersphere_dist': 6.0762834548950195,\n",
              " 'deepSVDD_label': 1}"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.predict_single_sequence(logseq)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
